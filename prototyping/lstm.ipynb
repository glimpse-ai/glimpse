{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import sys\n",
    "stdout = sys.stdout\n",
    "reload(sys)\n",
    "sys.setdefaultencoding('utf-8')\n",
    "sys.stdout = stdout\n",
    "import os\n",
    "sys.path.append('..')\n",
    "\n",
    "from glimpse.utils.layers import conv_1d, conv_2d, fully_connected\n",
    "from glimpse.utils.pixnet import conv_block\n",
    "from glimpse.utils import vocab\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import h5py\n",
    "\n",
    "print \"lol\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image_dims = [1250,640,3]\n",
    "data_dir = '/media/marsdenlab/Data2/glimpse/data/dataset.hdf5'\n",
    "data = h5py.File(data_dir, 'r')\n",
    "\n",
    "def train():\n",
    "  return get_dataset('train')\n",
    "\n",
    "\n",
    "def val():\n",
    "  return get_dataset('val')\n",
    "\n",
    "\n",
    "def test():\n",
    "  return get_dataset('test')\n",
    "\n",
    "\n",
    "def get_dataset(setname):\n",
    "  set = data.get(setname)\n",
    "\n",
    "  if not set:\n",
    "    raise BaseException('{} set does not exist yet in dataset'.format(setname))\n",
    "\n",
    "  return set.get('images'), set.get('labels'), set.get('label_lens')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, Y_train, train_label_lens = train()\n",
    "X_val, Y_val, val_label_lens = val()\n",
    "X_test, Y_test, test_label_lens = test()\n",
    "\n",
    "print X_train.shape\n",
    "print Y_train.shape\n",
    "print X_train[0].shape\n",
    "print train_label_lens[0]\n",
    "print np.amax(train_label_lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def repeat(x,axis,repeat):\n",
    "    s = x.get_shape().as_list()\n",
    "    splits = tf.split(value=x,num_or_size_splits=s[axis],axis=axis)\n",
    "    rep = [s for s in splits for _ in range(repeat)]\n",
    "    return tf.concat(rep,axis)\n",
    "\n",
    "def resize_tensor(x,scales=[1,2,2,2,1]):\n",
    "    out = x\n",
    "    for i in range(1,len(scales)):\n",
    "        out = repeat(out,i,scales[i])\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#network parameters\n",
    "batch_size = 1\n",
    "learning_rate = 1e-4\n",
    "train_steps = 10000\n",
    "print_step = 50\n",
    "num_filters = 32\n",
    "hidden_size = 1024\n",
    "filter_dims=[5,5]\n",
    "num_words = 50\n",
    "\n",
    "N = X_train.shape[0]\n",
    "Nval = X_val.shape[0]\n",
    "dml_length = Y_train.shape[1]-1\n",
    "vocab_length = Y_train.shape[2]\n",
    "\n",
    "def get_batch(X,Y,lab_len,N,n=32):\n",
    "    i = np.random.choice(range(N),size=n, replace=False)[0]\n",
    "    x = X[i]\n",
    "    y = Y[i]\n",
    "    l = lab_len[i]\n",
    "\n",
    "    x = x.reshape((1,x.shape[0],x.shape[1],x.shape[2]))\n",
    "    y = y.reshape((1,y.shape[0],y.shape[1]))\n",
    "    y = y[:,:dml_length,:]\n",
    "    \n",
    "    return x,y,l\n",
    "\n",
    "xb,yb,m = get_batch(X_train,Y_train,train_label_lens,N,batch_size)\n",
    "print xb.shape\n",
    "print yb.shape\n",
    "print m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rnn(x,h,hidden_size=100,activation=tf.nn.tanh,scope='RNN',reuse=False):\n",
    "    s = x.get_shape().as_list()\n",
    "    vocab_size = s[1]\n",
    "    \n",
    "    with tf.variable_scope(scope, reuse=reuse):\n",
    "            Wxh = tf.get_variable('Wxh', [vocab_size, hidden_size])\n",
    "            Whh = tf.get_variable('Whh', [hidden_size, hidden_size])\n",
    "            Why = tf.get_variable('Why', [hidden_size, hidden_size])\n",
    "            bh = tf.get_variable('bh', [hidden_size])\n",
    "            by = tf.get_variable('by', [hidden_size])\n",
    "    \n",
    "    next_state = activation(tf.matmul(x, Wxh) + tf.matmul(h, Whh) + bh)\n",
    "    yhat = tf.matmul(next_state,Why)+by\n",
    "    return yhat,next_state\n",
    "\n",
    "def lstm(x,h,hidden_size=100,activation=tf.nn.tanh,scope='RNN',reuse=False):\n",
    "    \n",
    "    Ct,ht = tf.split(h,2,axis=1)\n",
    "    \n",
    "    v = tf.concat([x,ht],axis=1)\n",
    "    s = v.get_shape().as_list()\n",
    "    v_size = s[1]\n",
    "    \n",
    "    with tf.variable_scope(scope, reuse=reuse):\n",
    "            Wf = tf.get_variable('Wf', [v_size, hidden_size])\n",
    "            Wi = tf.get_variable('Wi', [v_size, hidden_size])\n",
    "            Wc = tf.get_variable('Wc', [v_size, hidden_size])\n",
    "            Wo = tf.get_variable('Wo', [v_size, hidden_size])\n",
    "            bf = tf.get_variable('bf', [hidden_size])\n",
    "            bi = tf.get_variable('bi', [hidden_size])\n",
    "            bc = tf.get_variable('bc', [hidden_size])\n",
    "            bo = tf.get_variable('bo', [hidden_size])\n",
    "    \n",
    "    f = tf.nn.sigmoid(tf.matmul(v,Wf)+bf)\n",
    "    i = tf.nn.sigmoid(tf.matmul(v,Wi)+bi)\n",
    "    C = tf.tanh(tf.matmul(v,Wc)+bc)\n",
    "    \n",
    "    C_new = f*Ct + i*C\n",
    "    o = tf.matmul(v,Wo)+bo\n",
    "    h_new = tf.nn.sigmoid(o)*tf.tanh(C_new)\n",
    "    \n",
    "    next_hidden = tf.concat([C_new,h_new],axis=1)\n",
    "    yhat = activation(o)\n",
    "    \n",
    "    return yhat,next_hidden\n",
    "\n",
    "def rnn_multi(rnn_cell, rnn_input, init_state, hidden_size=100, activation=tf.nn.tanh, scope='RNN'):\n",
    "    outputs = []\n",
    "    state = init_state\n",
    "    reuse = False\n",
    "    for i in range(len(rnn_input)):\n",
    "            x = rnn_input[i]\n",
    "\n",
    "            if i > 0: reuse=True\n",
    "            output,state = rnn_cell(x,state,hidden_size,activation,scope,reuse)\n",
    "            outputs.append(output)\n",
    "    return outputs,state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#graph construction\n",
    "x_image = tf.placeholder(shape=[batch_size]+image_dims,dtype=tf.float32)\n",
    "\n",
    "x_words = tf.placeholder(shape=[batch_size,\n",
    "                          num_words,\n",
    "                          vocab_length],\n",
    "                   dtype=tf.float32)\n",
    "\n",
    "y = tf.placeholder(shape=[batch_size,\n",
    "                          num_words,\n",
    "                          vocab_length],\n",
    "                   dtype=tf.float32)\n",
    "\n",
    "mask = tf.placeholder(shape=[batch_size,dml_length],dtype=tf.float32)\n",
    "\n",
    "image_vec = conv_block(x_image,\n",
    "                      num_filters=num_filters,\n",
    "                      filter_dims=filter_dims,\n",
    "                      fc_size=hidden_size,\n",
    "                      batch_size=batch_size,\n",
    "                      scope='conv_block') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "C_1 = tf.placeholder(shape=[batch_size,2*hidden_size],dtype=tf.float32)\n",
    "C_2 = tf.placeholder(shape=[batch_size,2*vocab_length],dtype=tf.float32)\n",
    "\n",
    "print x_words[:,0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "outputs = []\n",
    "word = x_words[:,0,:]\n",
    "\n",
    "o_1,hidden_1 = lstm(word,C_1,hidden_size,scope='lstm_1')\n",
    "print o_1\n",
    "input_2 = tf.concat([o_1,image_vec],axis=1)\n",
    "print input_2\n",
    "o_2,hidden_2 = lstm(input_2,C_2,vocab_length,tf.identity,scope='lstm_2')\n",
    "\n",
    "outputs.append(o_2)\n",
    "\n",
    "reuse = True\n",
    "for i in range(1,num_words):\n",
    "    word = x_words[:,i,:]\n",
    "    o_1,hidden_1 = lstm(word,hidden_1,hidden_size,scope='lstm_1',reuse=reuse)\n",
    "    \n",
    "    inp = tf.concat([o_1,image_vec],axis=1)\n",
    "    \n",
    "    o_2,hidden_2 = lstm(inp,hidden_2,vocab_length,tf.identity,scope='lstm_2',reuse=reuse)\n",
    "    outputs.append(o_2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Test time tensors\n",
    "C_1_test = tf.placeholder(shape=[1,2*hidden_size],dtype=tf.float32)\n",
    "C_2_test = tf.placeholder(shape=[1,2*vocab_length],dtype=tf.float32)\n",
    "\n",
    "x_test = tf.placeholder(shape=[1,\n",
    "                          vocab_length],\n",
    "                   dtype=tf.float32)\n",
    "\n",
    "o_1_test, hidden_1_test = lstm(x_test,C_1_test,hidden_size,scope='lstm_1',reuse=True)\n",
    "\n",
    "cat_vec_test = tf.concat([o_1_test,image_vec],axis=1)\n",
    "\n",
    "o_2_test,hidden_2_test = lstm(cat_vec_test,C_2_test,vocab_length,tf.identity,scope='lstm_2', reuse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_tensor = tf.stack(outputs,axis=1)\n",
    "print output_tensor\n",
    "loss = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(logits=output_tensor,labels=y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "opt = tf.train.AdamOptimizer(learning_rate)\n",
    "train = opt.minimize(loss)\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-f6364640a924>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m             l,_,hid_1,hid_2=sess.run([loss,train,hidden_1,hidden_2],\n\u001b[1;32m     17\u001b[0m                                      {x_image:xb,y:label,x_words:inp_w,\n\u001b[0;32m---> 18\u001b[0;31m                                      C_1:hid_1,C_2:hid_2})\n\u001b[0m\u001b[1;32m     19\u001b[0m             \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/marsdenlab/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 778\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    779\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/marsdenlab/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    980\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 982\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    983\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/marsdenlab/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1030\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1032\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1033\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/home/marsdenlab/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1037\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1040\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/marsdenlab/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1019\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1020\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Start the train loop\n",
    "train_hist = []\n",
    "val_hist = []\n",
    "for i in range(train_steps):\n",
    "    xb,yb,l = get_batch(X_train,Y_train,train_label_lens,N,n=batch_size)\n",
    "    xb = xb/255\n",
    "    \n",
    "    hid_1 = np.zeros((1,2*hidden_size))\n",
    "    hid_2 = np.zeros((1,2*vocab_length))\n",
    "    \n",
    "    losses = []\n",
    "    for s in range(0,l,num_words):\n",
    "        inp_w = yb[:,s:s+num_words,:]\n",
    "        label = yb[:,s+1:s+num_words+1,:]\n",
    "        if inp_w.shape[1] == 50 and label.shape[1] == 50:\n",
    "            l,_,hid_1,hid_2=sess.run([loss,train,hidden_1,hidden_2],\n",
    "                                     {x_image:xb,y:label,x_words:inp_w,\n",
    "                                     C_1:hid_1,C_2:hid_2})\n",
    "            losses.append(l)\n",
    "\n",
    "    if i%print_step == 0:\n",
    "        losses = []\n",
    "        xb,yb,l = get_batch(X_val,Y_val,val_label_lens,Nval,n=batch_size)\n",
    "        xb = xb/255\n",
    "\n",
    "        hid_1 = np.zeros((1,2*hidden_size))\n",
    "        hid_2 = np.zeros((1,2*vocab_length))\n",
    "        for s in range(0,l,num_words):\n",
    "            inp_w = yb[:,s:s+num_words,:]\n",
    "            label = yb[:,s+1:s+num_words+1,:]\n",
    "            if inp_w.shape[1] == 50 and label.shape[1] == 50:\n",
    "                l,hid_1,hid_2=sess.run([loss,hidden_1,hidden_2],\n",
    "                                         {x_image:xb,y:label,x_words:inp_w,\n",
    "                                         C_1:hid_1,C_2:hid_2})\n",
    "                losses.append(l)\n",
    "        val_hist.append(np.mean(losses))\n",
    "        print \"iteration {} validation loss {}\".format(i,np.mean(losses))\n",
    "        \n",
    "    print \"iteration {} loss = {}\".format(i,np.mean(losses))\n",
    "    train_hist.append(np.mean(losses))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Nval = X_val.shape[0]\n",
    "j = np.random.randint(Nval)\n",
    "\n",
    "xb = X_val[j]\n",
    "print np.mean(xb)\n",
    "xb = xb.reshape((1,xb.shape[0],xb.shape[1],xb.shape[2]))\n",
    "yb = Y_val[j]\n",
    "print yb.shape\n",
    "xb = xb/255\n",
    "l = val_label_lens[j]\n",
    "print l\n",
    "hid_1 = np.zeros((1,2*hidden_size))\n",
    "hid_2 = np.zeros((1,2*vocab_length))\n",
    "w = yb[0]\n",
    "w = w.reshape((1,w.shape[0]))\n",
    "\n",
    "test_outputs = []\n",
    "test_words = []\n",
    "test_words.append(np.argmax(w))\n",
    "test_word_vecs = []\n",
    "for s in range(0,l+1):\n",
    "    #w = yb[s].reshape((1,vocab_length))\n",
    "    w,hid_1,hid_2=sess.run([o_2_test,hidden_1_test,hidden_2_test],\n",
    "                             {x_image:xb,x_test:w,\n",
    "                             C_1_test:hid_1,C_2_test:hid_2})\n",
    "\n",
    "    test_outputs.append(w)\n",
    "    w = np.exp(w)/(np.sum(np.exp(w)))\n",
    "    ind = np.argmax(w,axis=1)\n",
    "    w = np.zeros((1,vocab_length))\n",
    "    w[0,ind] = 1.0\n",
    "    test_words.append(ind)\n",
    "    test_word_vecs.append(w)\n",
    "    \n",
    "test_word_vecs = [t[0] for t in test_word_vecs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "print test_word_vecs[0].shape\n",
    "pred_dml = vocab.vec2dml(test_word_vecs)\n",
    "true_dml = vocab.vec2dml(yb)\n",
    "\n",
    "print pred_dml\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print true_dml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-7.03439856 -4.35251999 -4.98974371 -3.60547566 -8.59344482 -1.75788414\n",
      "  -4.54874563 -3.23316741 -0.05704202  9.56254005  7.46070433  7.84763098\n",
      "   5.88243961  6.79110861  5.24674749  5.89207125  3.17806077  0.88599384\n",
      "   2.55466986  1.80427575 -4.65884876 -2.9234488  -1.7151103  -1.18287385\n",
      "   0.61289287 -2.2666893  -1.6535809  -0.79557049 -0.2960757   0.28640857\n",
      "  -0.62646091 -2.48894596 -0.75227731  0.68062276 -0.83477861 -4.22519684\n",
      "  -2.93688464 -0.09119087 -2.96836758 -0.72797155 -1.84452939  1.28307867\n",
      "  -2.37805772  0.3214145  -1.48584116 -1.2636168  -2.72910953 -2.93743253\n",
      "   0.85114104 -2.29518914]]\n",
      "[[  4.32187761e-08   6.31535158e-07   3.33929478e-07   1.33301410e-06\n",
      "    9.09048925e-09   8.45733484e-06   5.19012474e-07   1.93431038e-06\n",
      "    4.63340111e-05   6.97639883e-01   8.52738023e-02   1.25561297e-01\n",
      "    1.75947864e-02   4.36529815e-02   9.31765046e-03   1.77650731e-02\n",
      "    1.17730012e-03   1.18974844e-04   6.31178147e-04   2.98029976e-04\n",
      "    4.64901149e-07   2.63654533e-06   8.82693621e-06   1.50299429e-05\n",
      "    9.05417546e-05   5.08466383e-06   9.38710946e-06   2.21391565e-05\n",
      "    3.64828629e-05   6.53218667e-05   2.62182930e-05   4.07134075e-06\n",
      "    2.31186805e-05   9.68865788e-05   2.12879168e-05   7.17287492e-07\n",
      "    2.60135812e-06   4.47784696e-05   2.52073551e-06   2.36874821e-05\n",
      "    7.75539684e-06   1.76972957e-04   4.54878682e-06   6.76490163e-05\n",
      "    1.11014651e-05   1.38640826e-05   3.20210597e-06   2.59993317e-06\n",
      "    1.14899674e-04   4.94179767e-06]]\n"
     ]
    }
   ],
   "source": [
    "print test_outputs[0]\n",
    "print np.exp(test_outputs[0])/(np.sum(np.exp(test_outputs[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./model'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saver = tf.train.Saver()\n",
    "saver.save(sess,'./model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "saver = tf.train.Saver()\n",
    "saver.restore(sess,'./model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
